<?xml version="1.0" encoding="UTF-8"?>
<AbstractBook>
 <Conference>Symposium on Nuclear Electronics and Computing - NEC'2019</Conference>
 <abstract>
  <Id>110</Id>
  <Title>Modernization of neutron Fourier chopper for High-resolution Fourier diffractometer (HRFD)</Title>
  <Content>The High-resolution Fourier diffractometer (HRFD) is operated at the pulsed reactor IBR-2 of FLNP JINR allowing to carry out precision research on the crystal structure and microstructure of inorganic materials. The use of the fast Fourier chopper both for intensity modulation of the primary neutron beam and the correlation method of diffraction data accumulation is the principal feature of the HRFD design. This allows to obtain extremely high resolution (Δd/d ≈ 0.001) at HRFD in a wide range of interplanar distances at a relatively short flight distance from the chopper to the sample position (L = 20 m). In 2016 the old Fourier-chopper (the operation period ~20 years) was replaced with a new one manufactured by the Mirrotron Ltd company (Hungary).  
The basic mechanical characteristics of the previous version of the Fourier chopper, particularly, the rotor diameter, the number of slits, the slit length, the slit width at the middle, the absorbing material Gd2O3 and the width of the layer Gd2O3, have been maintained in the new Fourier chopper for HRFD. The rotor is produced from the high-strength Al based alloy and allows maximum rotation speed of 6000 rpm. As compared to the previous version, the rotor and the stator are installed in a hermetic casing, the mechanical design of the stator allows to provide the exact configuration and fixation of the pick-up signal phase, a new type of incremental magnetic pickup sensor of the chopper disk rotation speed is applied with interpolation factor of 2 instead of 8, the rotor vacuum and vibration monitoring sensors are installed, a new control system for stator position is used. The new pick-up signal sensor and control system allowed to decrease the differential nonlinearity of the rotor instant speed up to ~2.5%.
The chopper control and monitoring system based on the software logic controller Omron provides the predefined law of change in the Fourier-chopper rotation speed and monitors the readings of vacuum, vibration and temperature control sensors.</Content>
  <field id="content">The High-resolution Fourier diffractometer (HRFD) is operated at the pulsed reactor IBR-2 of FLNP JINR allowing to carry out precision research on the crystal structure and microstructure of inorganic materials. The use of the fast Fourier chopper both for intensity modulation of the primary neutron beam and the correlation method of diffraction data accumulation is the principal feature of the HRFD design. This allows to obtain extremely high resolution (Δd/d ≈ 0.001) at HRFD in a wide range of interplanar distances at a relatively short flight distance from the chopper to the sample position (L = 20 m). In 2016 the old Fourier-chopper (the operation period ~20 years) was replaced with a new one manufactured by the Mirrotron Ltd company (Hungary).  
The basic mechanical characteristics of the previous version of the Fourier chopper, particularly, the rotor diameter, the number of slits, the slit length, the slit width at the middle, the absorbing material Gd2O3 and the width of the layer Gd2O3, have been maintained in the new Fourier chopper for HRFD. The rotor is produced from the high-strength Al based alloy and allows maximum rotation speed of 6000 rpm. As compared to the previous version, the rotor and the stator are installed in a hermetic casing, the mechanical design of the stator allows to provide the exact configuration and fixation of the pick-up signal phase, a new type of incremental magnetic pickup sensor of the chopper disk rotation speed is applied with interpolation factor of 2 instead of 8, the rotor vacuum and vibration monitoring sensors are installed, a new control system for stator position is used. The new pick-up signal sensor and control system allowed to decrease the differential nonlinearity of the rotor instant speed up to ~2.5%.
The chopper control and monitoring system based on the software logic controller Omron provides the predefined law of change in the Fourier-chopper rotation speed and monitors the readings of vacuum, vibration and temperature control sensors.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Nikolay</FirstName>
   <FamilyName>Zernin</FamilyName>
   <Email>nikolay-zernin@yandex.ru</Email>
   <Affiliation>JINR, FLNP, Department of Spectrometers Complex (DSC)</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Anatoly</FirstName>
   <FamilyName>Balagurov</FamilyName>
   <Email>bala@nf.jinr.ru</Email>
   <Affiliation>FLNP JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Dmitry</FirstName>
   <FamilyName>Balagurov</FamilyName>
   <Email>dbala@ya.ru</Email>
   <Affiliation>JINR, FLNP</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Ivan</FirstName>
   <FamilyName>Bobrikov</FamilyName>
   <Email>bobrikov@nf.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Svetlana</FirstName>
   <FamilyName>Murashkevich</FamilyName>
   <Email>svetlana@nf.jinr.ru</Email>
   <Affiliation>JINR FLNP</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Alexander</FirstName>
   <FamilyName>Sirotin</FamilyName>
   <Email>sirotin@nf.jinr.ru</Email>
   <Affiliation>JINR FLNP</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Tatiana</FirstName>
   <FamilyName>Petuhova</FamilyName>
   <Email>petukhova@jinr.ru</Email>
   <Affiliation>JINR FLNP</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Valery</FirstName>
   <FamilyName>Zhuravlev</FamilyName>
   <Email>zhur@nf.jinr.ru</Email>
   <Affiliation>JINR FLNP</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Gyula</FirstName>
   <FamilyName>Vasvari</FamilyName>
   <Email>vasvarigy@mirrotron.hu</Email>
   <Affiliation>Mirrotron Ltd, Hungary, Budapest</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Gabor</FirstName>
   <FamilyName>Szasz</FamilyName>
   <Email>szaszg@mirrotron.hu</Email>
   <Affiliation>Mirrotron Ltd, Hungary, Budapest</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Nikolay</FirstName>
   <FamilyName>Zernin</FamilyName>
   <Email>nikolay-zernin@yandex.ru</Email>
   <Affiliation>JINR, FLNP, Department of Spectrometers Complex (DSC)</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>111</Id>
  <Title>The automation of neutron activation analysis at IBR-2 reactor</Title>
  <Content>The automation of neutron activation analysis at IBR-2 reactor

 M.V. FRONTASYEVA, S.S. PAVLOV*, B.D.RUMYANTSEV, A.YU. DMITRIEV
Department of Neutron Activation Analysis and Applied Research
Division of Nuclear Physics, Frank Laboratory of Neutron Physics
Joint Institute for Nuclear Research, str. Joliot-Curie, 6, Dubna,  Russian Federation
*Correspondence: pavlov@nf.jinr.ru

 

The automation of neutron activation analysis (NAA) in the Joint Institute for Nuclear Research using the installation REGATA at the reactor IBR-2 of the Frank Laboratory of Neutron Physics, JINR, Dubna, RF is described. The database for acquisition of the information about all steps of NAA and statistical analysis of obtained results are presented. The construction of sample changer and software for automation of spectra measurement were developed and three sample changers were assembled. The program for quantitative determination of elemental content in samples, some additional programs and structure chart of software are described. Automation of Quality Control (QC) procedures is integrated in the software developed. Details of the design are shown.
The application of new software make it possible to use electronic circulation of documents. It is very comfortably taking into account a large distance between laboratories for sample preparation, irradiation and analysis of spectra. 
Key-Words: neutron activation analysis, sample changer, automation, software, concentration</Content>
  <field id="content">The automation of neutron activation analysis at IBR-2 reactor

 M.V. FRONTASYEVA, S.S. PAVLOV*, B.D.RUMYANTSEV, A.YU. DMITRIEV
Department of Neutron Activation Analysis and Applied Research
Division of Nuclear Physics, Frank Laboratory of Neutron Physics
Joint Institute for Nuclear Research, str. Joliot-Curie, 6, Dubna,  Russian Federation
*Correspondence: pavlov@nf.jinr.ru

 

The automation of neutron activation analysis (NAA) in the Joint Institute for Nuclear Research using the installation REGATA at the reactor IBR-2 of the Frank Laboratory of Neutron Physics, JINR, Dubna, RF is described. The database for acquisition of the information about all steps of NAA and statistical analysis of obtained results are presented. The construction of sample changer and software for automation of spectra measurement were developed and three sample changers were assembled. The program for quantitative determination of elemental content in samples, some additional programs and structure chart of software are described. Automation of Quality Control (QC) procedures is integrated in the software developed. Details of the design are shown.
The application of new software make it possible to use electronic circulation of documents. It is very comfortably taking into account a large distance between laboratories for sample preparation, irradiation and analysis of spectra. 
Key-Words: neutron activation analysis, sample changer, automation, software, concentration</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Sergey</FirstName>
   <FamilyName>Pavlov</FamilyName>
   <Email>pavlov@nf.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Marina</FirstName>
   <FamilyName>Frontasyeva</FamilyName>
   <Email>marin@nf.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Boris</FirstName>
   <FamilyName>Rumyantsev</FamilyName>
   <Email>bdrum@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Andrey</FirstName>
   <FamilyName>Dmitriev</FamilyName>
   <Email>dmitriev@sunse.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Sergey</FirstName>
   <FamilyName>Pavlov</FamilyName>
   <Email>pavlov@nf.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>112</Id>
  <Title>Modernization of the Management and Control System for the Cold Neutron Moderator at the Fast Pulsed Reactor</Title>
  <Content>The management and control system of the cold neutron moderator allows the engineering staff to monitor, in the process of its operation, the main parameters of the moderator, including the gas blower rotation speed, the consumption and temperature of helium, the vacuum in the jacket, and movement of pellets in the transport pipe. Today, complex upgrading of the cold neutron moderator at the fast pulsed reactor «IBR-2M» is under way. The paper presents the current version of the structure of the management and control system for the cold moderator. Interface convertors are used to connect the management and control equipment of the cold moderator to the computer. The main interface of the data acquisition and control system of the executive devices is RS-485. Specialized software has been created to operate the system of management and control of the cold neutron moderator.</Content>
  <field id="content">The management and control system of the cold neutron moderator allows the engineering staff to monitor, in the process of its operation, the main parameters of the moderator, including the gas blower rotation speed, the consumption and temperature of helium, the vacuum in the jacket, and movement of pellets in the transport pipe. Today, complex upgrading of the cold neutron moderator at the fast pulsed reactor «IBR-2M» is under way. The paper presents the current version of the structure of the management and control system for the cold moderator. Interface convertors are used to connect the management and control equipment of the cold moderator to the computer. The main interface of the data acquisition and control system of the executive devices is RS-485. Specialized software has been created to operate the system of management and control of the cold neutron moderator.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Alexey</FirstName>
   <FamilyName>Altynov</FamilyName>
   <Email>altbady@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Maxim</FirstName>
   <FamilyName>Bulavin</FamilyName>
   <Email>bulavin85@inbox.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Alexandr</FirstName>
   <FamilyName>Sitotin</FamilyName>
   <Email>sirotin@nf.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Alexey</FirstName>
   <FamilyName>Altynov</FamilyName>
   <Email>altbady@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>113</Id>
  <Title>Calculation of efficiency of cylindrical thermal neutron counter assemblies</Title>
  <Content>Cylindrical proportional counter assemblies are the main tool for observing neutron fluxes on many spectrometers. Optimization of geometric parameters of assemblies is of interest from the point of view of increasing homogeneity of efficiency and simplifying the design of the detector system. The calculation of efficiency of different variants of assembly designs consisting of 4 and 5 Helium-4-1 type counters has been carried out in the paper. GEANT-4 package has been used to simulate the operation of the modules designed to replace the old counters of the spectrometer NERA. The calculations have been compared with the experimental results.</Content>
  <field id="content">Cylindrical proportional counter assemblies are the main tool for observing neutron fluxes on many spectrometers. Optimization of geometric parameters of assemblies is of interest from the point of view of increasing homogeneity of efficiency and simplifying the design of the detector system. The calculation of efficiency of different variants of assembly designs consisting of 4 and 5 Helium-4-1 type counters has been carried out in the paper. GEANT-4 package has been used to simulate the operation of the modules designed to replace the old counters of the spectrometer NERA. The calculations have been compared with the experimental results.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Aleksey</FirstName>
   <FamilyName>Kurilkin</FamilyName>
   <Email>akurilkin@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Andrey</FirstName>
   <FamilyName>Churakov</FamilyName>
   <Email>churakov@nf.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Anton</FirstName>
   <FamilyName>Glazkov</FamilyName>
   <Email>xa08942870@student.karazin.ua</Email>
   <Affiliation>V. N. Karazin Kharkiv National University</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Aleksey</FirstName>
   <FamilyName>Kurilkin</FamilyName>
   <Email>akurilkin@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
 </abstract>
 <abstract>
  <Id>114</Id>
  <Title>The New Data Acquisition System MPD-32 for the High-Resolution Fourier Diffractometer at the IBR-2 Pulsed Reactor</Title>
  <Content>In the Laboratory of Neutron Physics a new high-performance data acquisition system (DAQ) is being developed in the framework of the project on creation of a high-aperture backscattering detector (BSD) for the high-resolution Fourier diffractometer HRFD. 

The designed increase in the BSD aperture of 12.5 times together with an increase in the neutron flux on the sample by a factor of 2-3 due to employment of the new neutron guide demand for raising the neutron registration rate to ~ 3*107 n/s [1].  In addition to signals from the multielement scintillation detector BSD, time encoders also digitize pick-up signals from the chopper as well as of reactor startups that are transmitted to the computer in the list mode to be recorded on the disk for further processing. This has required development of new electronics and programs as the MPD-240-based DAQ system used today has the neutron registration limit on the level of ~ 106 n / s.  
 
Earlier, in order to increase the transmission capacity of the data acquisition systems with a USB-2 interface for the IBR-2 spectrometers, the FLINK USB 3.0 was developed [2] to provide links between the modules having an optical interface with a computer according to the USB 3.0 protocol. This has solved the problem of increasing the performance of the DAQ systems for all the spectrometers except those for the HRFD that has undergone modernization. 
This work presents the results of development of a high-performance data acquisition system on the basis of MPD-32 blocks integrated into a common system of a high-speed interblock interface and an USB 3.0 computer interface with an optical fiber extender.</Content>
  <field id="content">In the Laboratory of Neutron Physics a new high-performance data acquisition system (DAQ) is being developed in the framework of the project on creation of a high-aperture backscattering detector (BSD) for the high-resolution Fourier diffractometer HRFD. 

The designed increase in the BSD aperture of 12.5 times together with an increase in the neutron flux on the sample by a factor of 2-3 due to employment of the new neutron guide demand for raising the neutron registration rate to ~ 3*107 n/s [1].  In addition to signals from the multielement scintillation detector BSD, time encoders also digitize pick-up signals from the chopper as well as of reactor startups that are transmitted to the computer in the list mode to be recorded on the disk for further processing. This has required development of new electronics and programs as the MPD-240-based DAQ system used today has the neutron registration limit on the level of ~ 106 n / s.  
 
Earlier, in order to increase the transmission capacity of the data acquisition systems with a USB-2 interface for the IBR-2 spectrometers, the FLINK USB 3.0 was developed [2] to provide links between the modules having an optical interface with a computer according to the USB 3.0 protocol. This has solved the problem of increasing the performance of the DAQ systems for all the spectrometers except those for the HRFD that has undergone modernization. 
This work presents the results of development of a high-performance data acquisition system on the basis of MPD-32 blocks integrated into a common system of a high-speed interblock interface and an USB 3.0 computer interface with an optical fiber extender.</field>
  <field id="summary">In the Laboratory of Neutron Physics a new high-performance data acquisition system (DAQ) is being developed in the framework of the project on creation of a high-aperture backscattering detector (BSD) for the high-resolution Fourier diffractometer HRFD. 

The designed increase in the BSD aperture of 12.5 times together with an increase in the neutron flux on the sample by a factor of 2-3 due to employment of the new neutron guide demand for raising the neutron registration rate to ~ 3*107 n/s [1].  In addition to signals from the multielement scintillation detector BSD, time encoders also digitize pick-up signals from the chopper as well as of reactor startups that are transmitted to the computer in the list mode to be recorded on the disk for further processing. This has required development of new electronics and programs as the MPD-240-based DAQ system used today has the neutron registration limit on the level of ~ 106 n / s.  
 
Earlier, in order to increase the transmission capacity of the data acquisition systems with a USB-2 interface for the IBR-2 spectrometers, the FLINK USB 3.0 was developed [2] to provide links between the modules having an optical interface with a computer according to the USB 3.0 protocol. This has solved the problem of increasing the performance of the DAQ systems for all the spectrometers except those for the HRFD that has undergone modernization. 
This work presents the results of development of a high-performance data acquisition system on the basis of MPD-32 blocks integrated into a common system of a high-speed interblock interface and an USB 3.0 computer interface with an optical fiber extender. 

References
[1]	A. Balagurov et al. «High-resolution neutron Fourier diffractometer at the IBR-2 pulsed reactor: A new concept». Nuclear Inst. and Methods in Physics Research B 436 (2018) 263–271.
[2]	Shvetsov V.V., V.A. Drozdov. "Increasing Bandwidth of Data Acquisition Systems on IBR-2 Reactor Spectrometers in FLNP". Proceedings of the XXVI International Symposium on Nuclear Electronics &amp; Computing (NEC’2017) Becici, Budva, Montenegro, September 25 - 29, 2017, European repository of the CEUR Workshop Proceedings Vol-2023, pp. 293-298.</field>
  <PrimaryAuthor>
   <FirstName>Vladimir</FirstName>
   <FamilyName>Drozdov</FamilyName>
   <Email>drozdov@jinr.ru</Email>
   <Affiliation>JINR, FLNP</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Svetlana</FirstName>
   <FamilyName>Murashkevich</FamilyName>
   <Email>svetlana@nf.jinr.ru</Email>
   <Affiliation>JINR FLNP</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Valentin</FirstName>
   <FamilyName>Prikhodko</FamilyName>
   <Email>prikh@nf.jinr.ru</Email>
   <Affiliation>JINR FLNP</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Aleksey</FirstName>
   <FamilyName>Bogdzel</FamilyName>
   <Email>abogdz@nf.jinr.ru</Email>
   <Affiliation>JINR FLNP</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Vasilii</FirstName>
   <FamilyName>Shvetsov</FamilyName>
   <Email>shvetc_vas@mail.ru</Email>
   <Affiliation>FLNP</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Vasilii</FirstName>
   <FamilyName>Shvetsov</FamilyName>
   <Email>shvetc_vas@mail.ru</Email>
   <Affiliation>FLNP</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>115</Id>
  <Title>Front-End Electronics for TPC/MPD detector of NICA project</Title>
  <Content>Time Projection Chamber (TPC) is the main tracker of the Multi-Purpose Detector (MPD). The detector will operate at one of beam interaction points of the collider NICA (Nuclotron-based Ion Collider fAcility) and it is optimized to investigate heavy-ion collisions in the energy range from 4 to 11 GeV/n. The TPC Front-End Electronics (FEE) will operate with event rate up to 7 kHz at average luminosity 1027 cm-2s-1 for gold collisions at 9 GeV/n. The FEE is based on the novel ASIC SAMPA, FPGAs and high-speed serial links. Each of 24 readout chambers will serve by 62 Front-End Cards (FECs) and one Readout and Control Unit (RCU). The whole system will contain 1488 FECs, 24 RCUs which gives us 95232 registration channels.
The report presents current status of the FEE and results of the FEC testing.</Content>
  <field id="content">Time Projection Chamber (TPC) is the main tracker of the Multi-Purpose Detector (MPD). The detector will operate at one of beam interaction points of the collider NICA (Nuclotron-based Ion Collider fAcility) and it is optimized to investigate heavy-ion collisions in the energy range from 4 to 11 GeV/n. The TPC Front-End Electronics (FEE) will operate with event rate up to 7 kHz at average luminosity 1027 cm-2s-1 for gold collisions at 9 GeV/n. The FEE is based on the novel ASIC SAMPA, FPGAs and high-speed serial links. Each of 24 readout chambers will serve by 62 Front-End Cards (FECs) and one Readout and Control Unit (RCU). The whole system will contain 1488 FECs, 24 RCUs which gives us 95232 registration channels.
The report presents current status of the FEE and results of the FEC testing.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Stepan</FirstName>
   <FamilyName>Vereschagin</FamilyName>
   <Email>vereschagin@jinr.ru</Email>
   <Affiliation>Joint Institute for Nuclear Research</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Stepan</FirstName>
   <FamilyName>Vereschagin</FamilyName>
   <Email>vereschagin@jinr.ru</Email>
   <Affiliation>Joint Institute for Nuclear Research</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>116</Id>
  <Title>Stand for the investigation radiation hardness of the plastic scintillators and reflectors</Title>
  <Content>Created the experimental stand for the investigation radiation hardness of the plastic scintillators. Studied two types on polystyrene based samples (UPS-923A and SCSN-81) and two types of  polyvinyltoluene based samples (BC-408 and EJ-260). 
Studied the radiation damage of ESR and Tyvek reflectors, Paint+TiO2 and PMS+TiO2 coatings.</Content>
  <field id="content">Created the experimental stand for the investigation radiation hardness of the plastic scintillators. Studied two types on polystyrene based samples (UPS-923A and SCSN-81) and two types of  polyvinyltoluene based samples (BC-408 and EJ-260). 
Studied the radiation damage of ESR and Tyvek reflectors, Paint+TiO2 and PMS+TiO2 coatings.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Valentin</FirstName>
   <FamilyName>Ustinov</FamilyName>
   <Email>ustinov@jinr.ru</Email>
   <Affiliation>JINR VBLHEP</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Evgeni</FirstName>
   <FamilyName>Sukhov</FamilyName>
   <Email>suhov@jinr.ru</Email>
   <Affiliation>LHE JINR</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Sergei</FirstName>
   <FamilyName>Afanasiev</FamilyName>
   <Email>afanasev@lhe.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Valentin</FirstName>
   <FamilyName>Ustinov</FamilyName>
   <Email>ustinov@jinr.ru</Email>
   <Affiliation>JINR VBLHEP</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
 </abstract>
 <abstract>
  <Id>117</Id>
  <Title>Distributed control and monitoring tools at LU-20 and HILAC complexes.</Title>
  <Content>The TANGO control system is chosen as the main platform for developing control software at the Nuclotron. The experimental setup of the TANGO system was successfully tested during the runs of the existing accelerator complex. The report describes hardware, server and client software modules for data acquisition and equipment management at LU-20 and HILAC linear accelerators.
	Universal web clients were developed for management of equipment groups. The data is transferred is a single stream for each group of equipment. The client layer interacts with TANGO control system via standard http and WebSocket protocols. It allows to significantly expand the choice of programming language for writing the client software. The TANGO device server WebSocketDS was developed for data exchange via WebSocket protocol.
	Various JavaScript libraries and frameworks were used for the client layer development, such as Angular, ReactJS, ExtJs and few others. They allow to create cross-platform client web applications for the control systems. JavaScript framework Electron was used for creating standard desktop applications.</Content>
  <field id="content">The TANGO control system is chosen as the main platform for developing control software at the Nuclotron. The experimental setup of the TANGO system was successfully tested during the runs of the existing accelerator complex. The report describes hardware, server and client software modules for data acquisition and equipment management at LU-20 and HILAC linear accelerators.
	Universal web clients were developed for management of equipment groups. The data is transferred is a single stream for each group of equipment. The client layer interacts with TANGO control system via standard http and WebSocket protocols. It allows to significantly expand the choice of programming language for writing the client software. The TANGO device server WebSocketDS was developed for data exchange via WebSocket protocol.
	Various JavaScript libraries and frameworks were used for the client layer development, such as Angular, ReactJS, ExtJs and few others. They allow to create cross-platform client web applications for the control systems. JavaScript framework Electron was used for creating standard desktop applications.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Vladimir</FirstName>
   <FamilyName>Elkin</FamilyName>
   <Email>elkin@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Dmitriy</FirstName>
   <FamilyName>Ponkin</FamilyName>
   <Email>ponkin@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Georgy</FirstName>
   <FamilyName>Sedykh</FamilyName>
   <Email>egor@dubna.tk</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Evgeny</FirstName>
   <FamilyName>Gorbachev</FamilyName>
   <Email>egorbe@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Vladimir</FirstName>
   <FamilyName>Elkin</FamilyName>
   <Email>elkin@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>118</Id>
  <Title>Present status and main directions of the JINR cloud development</Title>
  <Content>The JINR cloud grows not only in terms of amount of resources but in the number of activities they are used for: COMPASS production system services, data management system of the UNECE ICP Vegetation, service for diseases detection of agricultural crops through the use of advanced machine learning approaches, service for scientific and engineering computations, service for data visualization based on Grafana, jupyterhub head and execute nodes for it, gitlab and its runners as well as some other. All these topics are covered in details.</Content>
  <field id="content">The JINR cloud grows not only in terms of amount of resources but in the number of activities they are used for: COMPASS production system services, data management system of the UNECE ICP Vegetation, service for diseases detection of agricultural crops through the use of advanced machine learning approaches, service for scientific and engineering computations, service for data visualization based on Grafana, jupyterhub head and execute nodes for it, gitlab and its runners as well as some other. All these topics are covered in details.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Nikolay</FirstName>
   <FamilyName>Kutovskiy</FamilyName>
   <Email>kut@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Nikita</FirstName>
   <FamilyName>Balashov</FamilyName>
   <Email>balashov.nikita@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Alexandr</FirstName>
   <FamilyName>Baranov</FamilyName>
   <Email>baranov@jinr.ru</Email>
   <Affiliation>(JINR)</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Yelena</FirstName>
   <FamilyName>Mazhitova</FamilyName>
   <Email>emazhitova@jinr.ru</Email>
   <Affiliation>Joint Institute for Nuclear Research</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Roman</FirstName>
   <FamilyName>Semenov</FamilyName>
   <Email>roman@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Nikolay</FirstName>
   <FamilyName>Kutovskiy</FamilyName>
   <Email>kut@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Distributed Computing. GRID &amp; Cloud Computing</Track>
 </abstract>
 <abstract>
  <Id>119</Id>
  <Title>Development and Integration of the Electronic Logbook for the BM@N experiment at NICA</Title>
  <Content>The acquisition of experimental data is an integral part of all modern high-energy physics experiments. During experiment sessions, not only the data collected from the detectors are important for understanding the produced events, but also the records in logbooks that are written by the shift crew and describe operating modes of various systems and detectors and different types of events. The report shows a new electronic logbook developed to automate the latter process in the BM@N experiment, a fixed target experiment of the first stage of the NICA project at the Joint Institute for Nuclear Research. The online electronic logbook allows collaboration members during experiment runs to record information on current events, states of various systems, operation conditions of detectors and many others which are further used in the processing and physics analysis of the particle collision events. The system provides users with tools for convenient viewing, transparent managing and searching for the required information in the logbook. The specialized Web-interface and application programming interface for storing and accessing these data are considered. The important task of integrating the online electronic logbook with the central experiment database is also shown. The implementation of such information system is a necessary step for the successful future operation of the BM@N experiment.</Content>
  <field id="content">The acquisition of experimental data is an integral part of all modern high-energy physics experiments. During experiment sessions, not only the data collected from the detectors are important for understanding the produced events, but also the records in logbooks that are written by the shift crew and describe operating modes of various systems and detectors and different types of events. The report shows a new electronic logbook developed to automate the latter process in the BM@N experiment, a fixed target experiment of the first stage of the NICA project at the Joint Institute for Nuclear Research. The online electronic logbook allows collaboration members during experiment runs to record information on current events, states of various systems, operation conditions of detectors and many others which are further used in the processing and physics analysis of the particle collision events. The system provides users with tools for convenient viewing, transparent managing and searching for the required information in the logbook. The specialized Web-interface and application programming interface for storing and accessing these data are considered. The important task of integrating the online electronic logbook with the central experiment database is also shown. The implementation of such information system is a necessary step for the successful future operation of the BM@N experiment.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Konstantin</FirstName>
   <FamilyName>Gertsenberger</FamilyName>
   <Email>gertsen@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Andrey</FirstName>
   <FamilyName>Moshkin</FamilyName>
   <Email>andrem@thsun1.jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>alexandr</FirstName>
   <FamilyName>chebotov</FamilyName>
   <Email>lokzzzor@gmail.com</Email>
   <Affiliation>lit</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Konstantin</FirstName>
   <FamilyName>Gertsenberger</FamilyName>
   <Email>gertsen@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
  <Track>Research Data Infrastructures</Track>
  <Track>Non-relational Databases and Heterogeneous Repositories</Track>
 </abstract>
 <abstract>
  <Id>120</Id>
  <Title>Methodical aspects of training data scientists using the Data GRID in a virtual computer lab environment</Title>
  <Content>1. Introduction
The tasks of distributed data storage and processing, data mining and mathematical modeling based on these data are priorities within the agenda of the digital economy development program in the Russian Federation.
Today it is very important to train data scientists that serve as the bridge between cutting-edge technology and digital economy needs. It is important to teach them to improve access to big data, analytics tools, and innovative research methods. They also should be able to design and deploy Data GRID clusters use and advise on such tools as machine learning, natural language processing, web scraping, big data platforms, and data visualization techniques and their application to relevant business needs and public policy issues.
The aim of an innovative IT education is the possibility of training specialists who can effectively solve such problems as conducting researches that explores methods to harness technology and innovation to advance equity, mobility and inclusion in cities, building innovative data products and pipelines to produce novel data that can help tackle pressing issues from a new angle, building systems and processes to collect, analyze, and combine multiple sources of data in novel ways.

2. Hardware and software tools for educational process

In order to provide students with the opportunity to design the Data GRID cluster for personal researches in the field of data analysis and mathematical modeling, we decided to replace physical computers with virtual machines in the virtual computer lab, which was established at the Institute of System Analysis and Control since 2007 by our associate professor M. Belov.
The virtual computer lab (VCL) provides a set of software and hardware-based virtualization and containerizations tools that enable the flexible and on-demand provision and use of computing resources in the form of cloud Internet services with integrated knowledge management system based on the principles of self-organization, functioning as a homogeneous environment with elements of cognitive representation of internal operational resources based on visual models and partial automation of basic technological operations with expert system for carrying out research projects, resource-intensive computational calculations and tasks related to the development of complex corporate and other distributed information systems. The service also provides dedicated virtual servers for innovative projects that are carried out by students and staff at the Institute of System Analysis and Control.
The main features of a virtual computer lab are the principles of self-organization, which make the transition from a complex system of granular group security policies with a large number of restrictions to the formation of personal responsibility and respect for colleagues, which should be a solid foundation for strengthening and developing classical cultural values in the educational environment. [1-9]
Data GRID is the general term which utilize the multiple sites or clusters for distribute the processing and storage among them, so the Hadoop HDFS is a method or a way for data grid implementation since many other Hadoop frameworks like MapReduce or Spark used for distributed data processing.
Traditional GRID computing is a processor architecture that combines computer resources from various domains to reach a main objective. In grid computing, the computers on the network can work on a task together, thus functioning as a supercomputer. Another way to look at is that GRID computing is now the traditional high-performance system with a flavor of MPI. [10]
We look at GRID as a distributed system concept – a way to use computers distributed over a network to solve a problem. GRID is a group of physical machines connected to make a GRID Computer and Hadoop is the software running on these machines, therefore Hadoop is a subset of Grid computing.
In order to provide the ability to quickly deploy Data GRID clusters, we added new blade servers (to optimize the space they occupy in a server room) with SSD disks of increased wear resistance and increased RAM.
In order to minimize costs, we use the VMware vCenter technology platform with an integrated set of proprietary software tools, for the productive implementation of educational tasks.

3. The advantages of using the virtual computer lab in the educational process

The organization of an effective educational process for the goal-directed training of IT experts has demanded a speedy solution to the following problems: an often insufficient number of classroom hours for students to cover a necessary and sufficient set of practical exercises that help students learn complex information systems; on a typical personal computer with average capabilities it is impossible to get real practical experience working with multi-component Data GRID cluster because the hardware requirements for such systems often go beyond what is offered on typical home, office and laptop computers; the single-user license cost for some software components or professional technical support is too high, and in most cases, such a license is required only for the duration of the learning process.
The training of the «consumers» should be cut off in the process of the IT specialists’ education, and we should spare no effort to training of the «creative doers». For this purpose, it is important to study the ways of creating the information systems from the scratch, paying attention to the configuring and adjustment of the equipment, connection and integration of all the necessary parts of the system without any help, and only after that to accomplish issue-oriented tasks.
The data scientist of the future is an expert, which has not only the fundamental scientific knowledge, but he is a promising engineer with an outstanding potential and is able to compose and make the capable data analysis solutions suitable for the project. Only the skilled professionals of this level can create the right conditions for the science development and its practical applications at an increasing rate.
All above-mentioned problems can be solved in the virtual computer lab, which has become not only the innovative tool for the training of the high skilled IT specialists, but also a demanded space for the technical cooperation between a final-year student and a potential employer. It gives an opportunity to show qualification in real time, and to present the employer's problem in the virtual format and try to solve it together, attracting the young minds and sometimes people with different ways of thinking,  for example, the history of the neural network expansion and the idea of calculation of the back propagation errors, using the gradient descent method and so on.
A centralized management portal as well as a knowledge management system were created in order to manage the virtual computer laboratory. The need to create such a system was conditioned by the fact that students are able to learn about Data GRID clusters, so it is important to create a social network between all participants as well as to create an environment that allows pupils the opportunity to independently engage in such processes as the identification, acquisition, presentation, and use (distribution) of knowledge without the direct involvement of the instructor.
Methods of use (propagation) are directly related to storage methods and, consequently, the technological tools that may be used for the transmission of formal knowledge include knowledge bases with various search functionality; blogs, wikis, and social networks; "Wiki Textbooks" that allow all participants to collaboratively create and update educational content and exchange practical problems (including from real companies); as well as user blogs, forums, and group chat systems.
That is why the priority of the university is to create the most favorable conditions for the forming of the professional competence in IT, which will help the graduates to solve a wide range of the tasks, happening during all the stages of the Data GRID development, including the design itself. It is evident that to form the professional competence the students should do the following in order master a lot of literature, do many practical tasks and make research works on the modern data analysis systems, their deployment, maintenance and effective appliance for solving the problem-oriented tasks.
The main way to solve these problems has been to create a virtual computer lab that is able to solve the problem of insufficient computing and software resources and to provide an adequate level of technological and methodological support; to teach how to use cutting-edge technologies to work with distributed information systems on the example of Hadoop Data GRID Cluster; to organize group work with educational materials by involving users in the process of improving these materials and allowing them to communicate freely with each other on the basis of self-organizational principles.

4. The results of the educational process

Education is the process of facilitating learning, or the acquisition of knowledge, skills, values, beliefs, and habits. Educational methods include storytelling, discussion, teaching, training, and directed research. Technology can enhance relationships between teachers and students. When teachers effectively integrate technology into subject areas, teachers grow into roles of adviser, content expert, and coach. Technology helps make teaching and learning more meaningful and fun. Using Virtual Computer Lab students learn to design and deploy a Data GRID cluster based on Apache Hadoop software using most common topologies (Basic Horizontal topology, Federation topology, Monadic topology, Hierarchical topology, Hybrid Topology), perform basic cluster administration tasks, such as adding or removing hosts and service instances, changing the replication factor, adjusting the amount of allocated memory for execution containers, etc. Learners upload real-world data from various data sources into distributed HDFS file system, perform data rebalancing. Based on the uploaded data, they study the main components of the cluster and most important analytics tools (MapReduce, Spark and utility tools HUE, HCatalog, Hive, Impala, Pig Latin, Sqoop, Solr, Oozie, CDSW). For example, based on several tens of millions posts from technical forum, evaluate the popularity of programming languages, the effectiveness of moderation, the tonality of a statement on a given product, etc.

5. Conclusion
The results that we get specialists who can create Data GRID clusters and productively solve problems in corresponding application domains. Their jobs can focus on data management, analytics modeling, and business analysis. Data scientists can be real change-makers within an organization, offering insight that can illuminate the company’s trajectory toward its ultimate business goals. Data scientists are integral to supporting both leaders and developers in creating better products and paradigms. And as their role in big business becomes more and more important, they are in increasingly short supply.
The Institute of System Analysis and Control has achieved in improving the educational process represent strategic foundations for overcoming perhaps one of the most acute problems in modern education: the fact that it tends to respond to changes in the external environment weakly and slowly.
It should also be emphasized that the virtual computer lab has helped us provide an optimal and sustainable technological, educational-organizational, scientific-methodological, and regulatory-administrative environment for supporting innovative approaches to computer education. It promotes the integration of the scientific and educational potential of Dubna State University and the formation of industry and academic research partnerships with leading companies that are potential employers of graduates of the Institute of System Analysis and Control.

References
[1] Belov M.A., Kryukov Y.A., Miheev M.A., Lupanov P.E., Tokareva N.A., Cheremisina E.N., Improving the efficiency of mastering distributed information systems in a virtual computer lab based on the use of containerization and container orchestration technologies, Sovremennye informatsionnye tekhnologii i IT-obrazovanie. 2018, T.14. №4.
[2] Belov, M.A., Krukov, Y.A., Mikheev, M.A., Tokareva, N.A., Cheremisina, E.N. Essential aspects of it training technology for processing, storage and data mining using the virtual computer lab, CEUR Workshop Proceedings 2267, pp. 207-212, 2018.
[3] Belov M.A., Kryukov Y.A., Lupanov P.E., Miheev M.A., Cheremisina E.N., Koncepciya kognitivnogo vzaimodeystviya s virtual'noy komp'yuternoy laboratoriey na osnove vizual'nyh modeley i ehkspertnoy sistemy, Estestvennye i tekhnicheskie nauki, 2018, №10, S. 27-36.
[4] Belov M.A., Lupanov P.E., Tokareva N.A., Cheremisina E.N. Kontseptsiya usovershenstvovannoy arhitektury virtual'noy komp'yuternoy laboratorii dlya effektivnogo obucheniya spetsialistov po raspredelennym informatsionnym sistemam razlichnogo naznacheniya i instrumental'nym sredstvam proektirovaniya, Sovremennye informatsionnye tekhnologii i IT-obrazovanie. 2017. T. 13. № 1. S. 182-189.
[5] Cheremisina, E.N., Belov, M.A., Tokareva, N.A., Grishko, S.I., Sorokin, A.V. Embedding of containerization technology in the core of the Virtual Computing Lab, CEUR Workshop Proceedings 2023, pp. 299-302, 2018.
[6] Belov M.A., Cheremisina E.N., Potemkina S.V., Distance learning through distributed information systems using a virtual computer lab and knowledge management system, Journal of Emerging research and solutions in ICT, 2016.
[7] Lishilin M.V., Belov M.A., Tokareva N.A., Sorokin A.V., Kontseptual'naya model' sistemy upravleniya znaniyami dlya formirovaniya professional'nyh kompetentsiy v oblasti IT v srede virtual'noy komp'yuternoy laboratorii, Fundamental'nye issledovaniya. 2015. № 11-5. S. 886-890.
[8] Belov M.A., Lishilin M.V., Tokareva N.A., Antipov O.E., Ot virtual'noy komp'yuternoy laboratorii k upravleniyu znaniyami. Itogi i perspektivy, Kachestvo. Innovatsii. Obrazovanie. 2014. № 9 (112). S. 3-14.
[9] Cheremisina E.N., Belov M.A., Lishilin M.V., Integratsiya virtual'noy komp'yuternoy laboratorii i znanievogo prostranstva - novyy vzglyad na podgotovku vysokokvalifitsirovannyh it-spetsialistov, Sistemnyy analiz v nauke i obrazovanii. 2014. № 1 (23). S. 97-104.
[10] Foster, Ian., Kesselman, Carl  The Grid2: Blueprint for a New Computing Infrastructure. — Morgan Kaufmann Publishers. — ISBN ISBN 1-55860-475-8, 2003.</Content>
  <field id="content">1. Introduction
The tasks of distributed data storage and processing, data mining and mathematical modeling based on these data are priorities within the agenda of the digital economy development program in the Russian Federation.
Today it is very important to train data scientists that serve as the bridge between cutting-edge technology and digital economy needs. It is important to teach them to improve access to big data, analytics tools, and innovative research methods. They also should be able to design and deploy Data GRID clusters use and advise on such tools as machine learning, natural language processing, web scraping, big data platforms, and data visualization techniques and their application to relevant business needs and public policy issues.
The aim of an innovative IT education is the possibility of training specialists who can effectively solve such problems as conducting researches that explores methods to harness technology and innovation to advance equity, mobility and inclusion in cities, building innovative data products and pipelines to produce novel data that can help tackle pressing issues from a new angle, building systems and processes to collect, analyze, and combine multiple sources of data in novel ways.

2. Hardware and software tools for educational process

In order to provide students with the opportunity to design the Data GRID cluster for personal researches in the field of data analysis and mathematical modeling, we decided to replace physical computers with virtual machines in the virtual computer lab, which was established at the Institute of System Analysis and Control since 2007 by our associate professor M. Belov.
The virtual computer lab (VCL) provides a set of software and hardware-based virtualization and containerizations tools that enable the flexible and on-demand provision and use of computing resources in the form of cloud Internet services with integrated knowledge management system based on the principles of self-organization, functioning as a homogeneous environment with elements of cognitive representation of internal operational resources based on visual models and partial automation of basic technological operations with expert system for carrying out research projects, resource-intensive computational calculations and tasks related to the development of complex corporate and other distributed information systems. The service also provides dedicated virtual servers for innovative projects that are carried out by students and staff at the Institute of System Analysis and Control.
The main features of a virtual computer lab are the principles of self-organization, which make the transition from a complex system of granular group security policies with a large number of restrictions to the formation of personal responsibility and respect for colleagues, which should be a solid foundation for strengthening and developing classical cultural values in the educational environment. [1-9]
Data GRID is the general term which utilize the multiple sites or clusters for distribute the processing and storage among them, so the Hadoop HDFS is a method or a way for data grid implementation since many other Hadoop frameworks like MapReduce or Spark used for distributed data processing.
Traditional GRID computing is a processor architecture that combines computer resources from various domains to reach a main objective. In grid computing, the computers on the network can work on a task together, thus functioning as a supercomputer. Another way to look at is that GRID computing is now the traditional high-performance system with a flavor of MPI. [10]
We look at GRID as a distributed system concept – a way to use computers distributed over a network to solve a problem. GRID is a group of physical machines connected to make a GRID Computer and Hadoop is the software running on these machines, therefore Hadoop is a subset of Grid computing.
In order to provide the ability to quickly deploy Data GRID clusters, we added new blade servers (to optimize the space they occupy in a server room) with SSD disks of increased wear resistance and increased RAM.
In order to minimize costs, we use the VMware vCenter technology platform with an integrated set of proprietary software tools, for the productive implementation of educational tasks.

3. The advantages of using the virtual computer lab in the educational process

The organization of an effective educational process for the goal-directed training of IT experts has demanded a speedy solution to the following problems: an often insufficient number of classroom hours for students to cover a necessary and sufficient set of practical exercises that help students learn complex information systems; on a typical personal computer with average capabilities it is impossible to get real practical experience working with multi-component Data GRID cluster because the hardware requirements for such systems often go beyond what is offered on typical home, office and laptop computers; the single-user license cost for some software components or professional technical support is too high, and in most cases, such a license is required only for the duration of the learning process.
The training of the «consumers» should be cut off in the process of the IT specialists’ education, and we should spare no effort to training of the «creative doers». For this purpose, it is important to study the ways of creating the information systems from the scratch, paying attention to the configuring and adjustment of the equipment, connection and integration of all the necessary parts of the system without any help, and only after that to accomplish issue-oriented tasks.
The data scientist of the future is an expert, which has not only the fundamental scientific knowledge, but he is a promising engineer with an outstanding potential and is able to compose and make the capable data analysis solutions suitable for the project. Only the skilled professionals of this level can create the right conditions for the science development and its practical applications at an increasing rate.
All above-mentioned problems can be solved in the virtual computer lab, which has become not only the innovative tool for the training of the high skilled IT specialists, but also a demanded space for the technical cooperation between a final-year student and a potential employer. It gives an opportunity to show qualification in real time, and to present the employer's problem in the virtual format and try to solve it together, attracting the young minds and sometimes people with different ways of thinking,  for example, the history of the neural network expansion and the idea of calculation of the back propagation errors, using the gradient descent method and so on.
A centralized management portal as well as a knowledge management system were created in order to manage the virtual computer laboratory. The need to create such a system was conditioned by the fact that students are able to learn about Data GRID clusters, so it is important to create a social network between all participants as well as to create an environment that allows pupils the opportunity to independently engage in such processes as the identification, acquisition, presentation, and use (distribution) of knowledge without the direct involvement of the instructor.
Methods of use (propagation) are directly related to storage methods and, consequently, the technological tools that may be used for the transmission of formal knowledge include knowledge bases with various search functionality; blogs, wikis, and social networks; "Wiki Textbooks" that allow all participants to collaboratively create and update educational content and exchange practical problems (including from real companies); as well as user blogs, forums, and group chat systems.
That is why the priority of the university is to create the most favorable conditions for the forming of the professional competence in IT, which will help the graduates to solve a wide range of the tasks, happening during all the stages of the Data GRID development, including the design itself. It is evident that to form the professional competence the students should do the following in order master a lot of literature, do many practical tasks and make research works on the modern data analysis systems, their deployment, maintenance and effective appliance for solving the problem-oriented tasks.
The main way to solve these problems has been to create a virtual computer lab that is able to solve the problem of insufficient computing and software resources and to provide an adequate level of technological and methodological support; to teach how to use cutting-edge technologies to work with distributed information systems on the example of Hadoop Data GRID Cluster; to organize group work with educational materials by involving users in the process of improving these materials and allowing them to communicate freely with each other on the basis of self-organizational principles.

4. The results of the educational process

Education is the process of facilitating learning, or the acquisition of knowledge, skills, values, beliefs, and habits. Educational methods include storytelling, discussion, teaching, training, and directed research. Technology can enhance relationships between teachers and students. When teachers effectively integrate technology into subject areas, teachers grow into roles of adviser, content expert, and coach. Technology helps make teaching and learning more meaningful and fun. Using Virtual Computer Lab students learn to design and deploy a Data GRID cluster based on Apache Hadoop software using most common topologies (Basic Horizontal topology, Federation topology, Monadic topology, Hierarchical topology, Hybrid Topology), perform basic cluster administration tasks, such as adding or removing hosts and service instances, changing the replication factor, adjusting the amount of allocated memory for execution containers, etc. Learners upload real-world data from various data sources into distributed HDFS file system, perform data rebalancing. Based on the uploaded data, they study the main components of the cluster and most important analytics tools (MapReduce, Spark and utility tools HUE, HCatalog, Hive, Impala, Pig Latin, Sqoop, Solr, Oozie, CDSW). For example, based on several tens of millions posts from technical forum, evaluate the popularity of programming languages, the effectiveness of moderation, the tonality of a statement on a given product, etc.

5. Conclusion
The results that we get specialists who can create Data GRID clusters and productively solve problems in corresponding application domains. Their jobs can focus on data management, analytics modeling, and business analysis. Data scientists can be real change-makers within an organization, offering insight that can illuminate the company’s trajectory toward its ultimate business goals. Data scientists are integral to supporting both leaders and developers in creating better products and paradigms. And as their role in big business becomes more and more important, they are in increasingly short supply.
The Institute of System Analysis and Control has achieved in improving the educational process represent strategic foundations for overcoming perhaps one of the most acute problems in modern education: the fact that it tends to respond to changes in the external environment weakly and slowly.
It should also be emphasized that the virtual computer lab has helped us provide an optimal and sustainable technological, educational-organizational, scientific-methodological, and regulatory-administrative environment for supporting innovative approaches to computer education. It promotes the integration of the scientific and educational potential of Dubna State University and the formation of industry and academic research partnerships with leading companies that are potential employers of graduates of the Institute of System Analysis and Control.

References
[1] Belov M.A., Kryukov Y.A., Miheev M.A., Lupanov P.E., Tokareva N.A., Cheremisina E.N., Improving the efficiency of mastering distributed information systems in a virtual computer lab based on the use of containerization and container orchestration technologies, Sovremennye informatsionnye tekhnologii i IT-obrazovanie. 2018, T.14. №4.
[2] Belov, M.A., Krukov, Y.A., Mikheev, M.A., Tokareva, N.A., Cheremisina, E.N. Essential aspects of it training technology for processing, storage and data mining using the virtual computer lab, CEUR Workshop Proceedings 2267, pp. 207-212, 2018.
[3] Belov M.A., Kryukov Y.A., Lupanov P.E., Miheev M.A., Cheremisina E.N., Koncepciya kognitivnogo vzaimodeystviya s virtual'noy komp'yuternoy laboratoriey na osnove vizual'nyh modeley i ehkspertnoy sistemy, Estestvennye i tekhnicheskie nauki, 2018, №10, S. 27-36.
[4] Belov M.A., Lupanov P.E., Tokareva N.A., Cheremisina E.N. Kontseptsiya usovershenstvovannoy arhitektury virtual'noy komp'yuternoy laboratorii dlya effektivnogo obucheniya spetsialistov po raspredelennym informatsionnym sistemam razlichnogo naznacheniya i instrumental'nym sredstvam proektirovaniya, Sovremennye informatsionnye tekhnologii i IT-obrazovanie. 2017. T. 13. № 1. S. 182-189.
[5] Cheremisina, E.N., Belov, M.A., Tokareva, N.A., Grishko, S.I., Sorokin, A.V. Embedding of containerization technology in the core of the Virtual Computing Lab, CEUR Workshop Proceedings 2023, pp. 299-302, 2018.
[6] Belov M.A., Cheremisina E.N., Potemkina S.V., Distance learning through distributed information systems using a virtual computer lab and knowledge management system, Journal of Emerging research and solutions in ICT, 2016.
[7] Lishilin M.V., Belov M.A., Tokareva N.A., Sorokin A.V., Kontseptual'naya model' sistemy upravleniya znaniyami dlya formirovaniya professional'nyh kompetentsiy v oblasti IT v srede virtual'noy komp'yuternoy laboratorii, Fundamental'nye issledovaniya. 2015. № 11-5. S. 886-890.
[8] Belov M.A., Lishilin M.V., Tokareva N.A., Antipov O.E., Ot virtual'noy komp'yuternoy laboratorii k upravleniyu znaniyami. Itogi i perspektivy, Kachestvo. Innovatsii. Obrazovanie. 2014. № 9 (112). S. 3-14.
[9] Cheremisina E.N., Belov M.A., Lishilin M.V., Integratsiya virtual'noy komp'yuternoy laboratorii i znanievogo prostranstva - novyy vzglyad na podgotovku vysokokvalifitsirovannyh it-spetsialistov, Sistemnyy analiz v nauke i obrazovanii. 2014. № 1 (23). S. 97-104.
[10] Foster, Ian., Kesselman, Carl  The Grid2: Blueprint for a New Computing Infrastructure. — Morgan Kaufmann Publishers. — ISBN ISBN 1-55860-475-8, 2003.</field>
  <field id="summary">This paper discusses methodical aspects of training data scientists using the data grid in a virtual computer lab environment. Data scientists serve as the bridge between cutting-edge technology and digital economy needs. It is important to teach them to improve access to big data, analytics tools, and innovative research methods. They also should be able to design and deploy Data GRID clusters use and advise on such tools as machine learning, natural language processing, web scraping, big data platforms, and data visualization techniques and their application to relevant business needs and public policy issues. Virtual computer lab is a powerful innovative tool for training IT-professionals, created and successfully operated by the experts of the System Analysis and Control Department at the Dubna State University. 

Keywords: virtual computer lab, virtualization, containerization, Grid, Data Grid, Hadoop, Map Reduce, Spark, HCatalog, Hive, Impala, Solr, Sqoop, Hue, cluster, data mining, distributed systems, mathematical modeling, education, data analytics, IT training, IT education, innovative education.</field>
  <PrimaryAuthor>
   <FirstName>Mikhail</FirstName>
   <FamilyName>Belov</FamilyName>
   <Email>belov@uni-dubna.ru</Email>
   <Affiliation>Dubna State Univeristy</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Vladimir</FirstName>
   <FamilyName>Korenkov</FamilyName>
   <Email>korenkov@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Nadezhda</FirstName>
   <FamilyName>Tokareva</FamilyName>
   <Email>tokareva@uni-dubna.ru</Email>
   <Affiliation>Dubna Univeristy</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Evgenia</FirstName>
   <FamilyName>Cheremisina</FamilyName>
   <Email>kirpicheva77@gmail.com</Email>
   <Affiliation>Dubna International University of Nature, Society and Man. Institute of system analysis and management</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Snezhana</FirstName>
   <FamilyName>Potemkina</FamilyName>
   <Email>snezhik@mail.ru</Email>
   <Affiliation>Dubna State University</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Vladimir</FirstName>
   <FamilyName>Korenkov</FamilyName>
   <Email>korenkov@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>None</ContributionType>
  <Track>Innovative IT Education</Track>
  <Track>Distributed Computing. GRID &amp; Cloud Computing</Track>
  <Track>Non-relational Databases and Heterogeneous Repositories</Track>
  <Track>Machine Learning Algorithms and Big Data Analytics</Track>
 </abstract>
 <abstract>
  <Id>121</Id>
  <Title>CompactRIO based Mössbauer spectrometer</Title>
  <Content>This talk reports the development of a new Mössbauer spectrometer based on modular DAQ devices and virtual instrumentation technique. Virtual instrumentation is new technology, which is used for development of measurement and test systems. It allows replacing complex analog circuits with computers and software. Thanks to this technology, it is now possible to easily create complex automatic control systems, that allow you to implement processes with e.g. self-diagnosis or self-setup, and who do not need the immediate presence of an operator because their management may be possible via the Internet or those system can be completely autonomous. Another technology that is becoming increasingly important are FPGA (Field Programmable Gate Arrays). Because of their configurability, determinism and speed have found widespread use in many areas where there is need for great computing power - even in nuclear physics. This talk will deal with combining those two new technologies for creating Mössbauer spectrometer. Mössbauer spectrometery is spectrometric method, which uses Mössbauer effect - recoilless emission and absorbtion of gamma rays by certain nuclei. Developed Mössbauer spectrometer is based on modular industrial computer CompactRIO by National Instruments™. This device has integrated FPGA, which is used for most critical functions, as DAQ, spectra processing and driving of transducer movement. The first part deals with the development of spectrometric application on a CompactRIO, that performs velocity reference signal generation, velocity transducer PID regulation, detector signal acquisition and spectrum registration. The second part deals with PID parameters autotuning using evolution algorithms and additional spectra linearization methods implemented in developed Mössbauer spectrometer.</Content>
  <field id="content">This talk reports the development of a new Mössbauer spectrometer based on modular DAQ devices and virtual instrumentation technique. Virtual instrumentation is new technology, which is used for development of measurement and test systems. It allows replacing complex analog circuits with computers and software. Thanks to this technology, it is now possible to easily create complex automatic control systems, that allow you to implement processes with e.g. self-diagnosis or self-setup, and who do not need the immediate presence of an operator because their management may be possible via the Internet or those system can be completely autonomous. Another technology that is becoming increasingly important are FPGA (Field Programmable Gate Arrays). Because of their configurability, determinism and speed have found widespread use in many areas where there is need for great computing power - even in nuclear physics. This talk will deal with combining those two new technologies for creating Mössbauer spectrometer. Mössbauer spectrometery is spectrometric method, which uses Mössbauer effect - recoilless emission and absorbtion of gamma rays by certain nuclei. Developed Mössbauer spectrometer is based on modular industrial computer CompactRIO by National Instruments™. This device has integrated FPGA, which is used for most critical functions, as DAQ, spectra processing and driving of transducer movement. The first part deals with the development of spectrometric application on a CompactRIO, that performs velocity reference signal generation, velocity transducer PID regulation, detector signal acquisition and spectrum registration. The second part deals with PID parameters autotuning using evolution algorithms and additional spectra linearization methods implemented in developed Mössbauer spectrometer.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Pavel</FirstName>
   <FamilyName>Kohout</FamilyName>
   <Email>pvlkohout@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Jiri</FirstName>
   <FamilyName>Pechousek</FamilyName>
   <Email>jiri.pechousek@upol.cz</Email>
   <Affiliation>Palacký University Olomouc</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Lukas</FirstName>
   <FamilyName>Kouril</FamilyName>
   <Email>lukas.kouril@upol.cz</Email>
   <Affiliation>Palacký University Olomouc</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Pavel</FirstName>
   <FamilyName>Kohout</FamilyName>
   <Email>pvlkohout@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>122</Id>
  <Title>Improvements in the NOvA Detector Simulation based on JINR stand measurements</Title>
  <Content>NOvA is a long-baseline neutrino experiment aiming to study neutrino oscillation phenomenon in the muon neutrino beam from complex NuMI at Fermilab (USA). Two identical detectors have been built to measure the initial neutrino flux spectra at the near site and the oscillated one at a 810 km distance, which significantly reduces many systematic uncertainties. To improve electron neutrino and neutral current interaction separation, the detector is constructed as a finely segmented structure filled with liquid scintillator. Charged particles lose their energy in the detector materials, producing light signal in a cell which are recorded by readout electronics. The simulation models this using the following chain: a parameterized front-end simulation converts all energy deposits in active material into scintillation light, the scintillation light is transported through an optical fiber to an avalanche photodiode, and the readout electronics simulation models the shaping, digitization, and triggering on the response of the photodiode. Two test stands have been built in JINR (Dubna, Russia) to measure the proton light response of NOvA scintillator and the electronic signal shaping of the NOvA front-end-board. The parameters measured using these test stands have been implemented in the custom NOvA simulation chain.</Content>
  <field id="content">NOvA is a long-baseline neutrino experiment aiming to study neutrino oscillation phenomenon in the muon neutrino beam from complex NuMI at Fermilab (USA). Two identical detectors have been built to measure the initial neutrino flux spectra at the near site and the oscillated one at a 810 km distance, which significantly reduces many systematic uncertainties. To improve electron neutrino and neutral current interaction separation, the detector is constructed as a finely segmented structure filled with liquid scintillator. Charged particles lose their energy in the detector materials, producing light signal in a cell which are recorded by readout electronics. The simulation models this using the following chain: a parameterized front-end simulation converts all energy deposits in active material into scintillation light, the scintillation light is transported through an optical fiber to an avalanche photodiode, and the readout electronics simulation models the shaping, digitization, and triggering on the response of the photodiode. Two test stands have been built in JINR (Dubna, Russia) to measure the proton light response of NOvA scintillator and the electronic signal shaping of the NOvA front-end-board. The parameters measured using these test stands have been implemented in the custom NOvA simulation chain.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Oleg</FirstName>
   <FamilyName>Samoylov</FamilyName>
   <Email>samoylov@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Oleg</FirstName>
   <FamilyName>Samoylov</FamilyName>
   <Email>samoylov@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
 </abstract>
 <abstract>
  <Id>123</Id>
  <Title>Trigger and beam monitoring system of BM@N and SRC experiments</Title>
  <Content>The report describes a Trigger module control and monitoring system used at experiments BM@N and SRC held in JINR. The system includes both hardware and software and allows to control trigger system including delays setting, discriminator level adjusting and trigger logics selection with few mouse clicks  without human access to the electronics. System also provides on-line beam and trigger intensity publishing using web and TSP/IP servers.</Content>
  <field id="content">The report describes a Trigger module control and monitoring system used at experiments BM@N and SRC held in JINR. The system includes both hardware and software and allows to control trigger system including delays setting, discriminator level adjusting and trigger logics selection with few mouse clicks  without human access to the electronics. System also provides on-line beam and trigger intensity publishing using web and TSP/IP servers.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Sergey</FirstName>
   <FamilyName>Sergeev</FamilyName>
   <Email>serguei.sergueev@mail.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Dmitri</FirstName>
   <FamilyName>Bogoslovski</FamilyName>
   <Email>bogoslovski.dimson@mail.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Victor</FirstName>
   <FamilyName>Rogov</FamilyName>
   <Email>rogovictor@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Vladimir</FirstName>
   <FamilyName>Yurevich</FamilyName>
   <Email>yurevich@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Sergey</FirstName>
   <FamilyName>Sergeev</FamilyName>
   <Email>serguei.sergueev@mail.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>124</Id>
  <Title>Project of a fast interaction trigger for MPD experiment</Title>
  <Content>The Fast Forward Detector based Level 0 Trigger system architecture is described. The system must provide fast and effective triggering on nucleus – nucleus collisions at the center of the setup with high efficiency for central and semi-central Au + Au collisions. It should  identify z- position of the collision with uncertainty better than 5 cm and an event multiplicity in pseudorapidity interval of 2.7 &lt; |η| &lt; 4.1. The system is modular and consists of two arm signal processors and a vertex processor. FPGAs are widely used.</Content>
  <field id="content">The Fast Forward Detector based Level 0 Trigger system architecture is described. The system must provide fast and effective triggering on nucleus – nucleus collisions at the center of the setup with high efficiency for central and semi-central Au + Au collisions. It should  identify z- position of the collision with uncertainty better than 5 cm and an event multiplicity in pseudorapidity interval of 2.7 &lt; |η| &lt; 4.1. The system is modular and consists of two arm signal processors and a vertex processor. FPGAs are widely used.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Sergey</FirstName>
   <FamilyName>Sergeev</FamilyName>
   <Email>serguei.sergueev@mail.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Victor</FirstName>
   <FamilyName>Rogov</FamilyName>
   <Email>rogovictor@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Vladimir</FirstName>
   <FamilyName>Yurevich</FamilyName>
   <Email>yurevich@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Sergey</FirstName>
   <FamilyName>Sergeev</FamilyName>
   <Email>serguei.sergueev@mail.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>125</Id>
  <Title>Electronics of the fission fragments spectrometer "COMETA-F"</Title>
  <Content>The article describes the electronics for the time-of-flight two-arm fission fragments spectrometer COMETA-F. The installation is constructed of ‘’Start’’ detector on the base of microchannel plates and mosaics of eight PiN diodes. Each PiN diode of 18x18 mm surface area provides both energy and timing signal. The waveform is digitized by V1742 modules with a speed of 5 Gs / s. Start for registration is provided by V945 discriminators and a specially designed trigger block.</Content>
  <field id="content">The article describes the electronics for the time-of-flight two-arm fission fragments spectrometer COMETA-F. The installation is constructed of ‘’Start’’ detector on the base of microchannel plates and mosaics of eight PiN diodes. Each PiN diode of 18x18 mm surface area provides both energy and timing signal. The waveform is digitized by V1742 modules with a speed of 5 Gs / s. Start for registration is provided by V945 discriminators and a specially designed trigger block.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Oleg</FirstName>
   <FamilyName>Strekalovsky</FamilyName>
   <Email>stroleg1@yandex.ru</Email>
   <Affiliation>JINR FLNR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Dmitry</FirstName>
   <FamilyName>Kamanin</FamilyName>
   <Email>kamanin@jinr.ru</Email>
   <Affiliation>Joint Institute for Nuclear Research</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Yury</FirstName>
   <FamilyName>Pyatkov</FamilyName>
   <Email>yvp_nov@mail.ru</Email>
   <Affiliation>National Nuclear Research University “MEPHI” &amp;amp; Joint Institute for Nuclear Research</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Alexandr</FirstName>
   <FamilyName>Strekalovsky</FamilyName>
   <Email>alex.strek@bk.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Oleg</FirstName>
   <FamilyName>Strekalovsky</FamilyName>
   <Email>stroleg1@yandex.ru</Email>
   <Affiliation>JINR FLNR</Affiliation>
  </Speaker>
  <ContributionType>None</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>126</Id>
  <Title>Design of the front-end electronics based on multichannel IDEAS ASICs for silicon and GEM detectors</Title>
  <Content>IDEAS ASICs are designed for the front-end readout of ionizing radiation detectors and produced by commercial fabless IC supplier – Integrated Detector Electronics AS (Norway). IDEAS ASIC is a multichannel (32/ 64/ 128) chips. Each chip channel has pre-amplifiers, shaper and multiplexed analogue readout. It’s necessary to configure internal chip registers, control analogue readout and transmit data from each measuring channel to DAQ System. These are basic functions of Control Unit based on FPGA. Design of the front-end electronics for silicon and GEM detectors consists of IDEAS IC, ADC and Control Unit.

Current FEE BM@N configuration (March 2018) is based on IDEAS ASICs for Forward Silicon Detector, GEM detectors and CSC. According to upgrade plans for BM@N FEE for Si beam tracker, Si beam profiler, Forward Silicon Tracking Detectors also will be based on the same ASICs. This paper presents the design of the front-end electronics of the BM@N Si beam profiler:

 - Double-Sided Silicon Detectors – a coordinate plane with 2x128 measuring channels;
 - IDEAS ASICs – the front-end readout of DSSD;
 - Analog Devices ADC;
 - FPGA Xilinx – Control Unit.</Content>
  <field id="content">IDEAS ASICs are designed for the front-end readout of ionizing radiation detectors and produced by commercial fabless IC supplier – Integrated Detector Electronics AS (Norway). IDEAS ASIC is a multichannel (32/ 64/ 128) chips. Each chip channel has pre-amplifiers, shaper and multiplexed analogue readout. It’s necessary to configure internal chip registers, control analogue readout and transmit data from each measuring channel to DAQ System. These are basic functions of Control Unit based on FPGA. Design of the front-end electronics for silicon and GEM detectors consists of IDEAS IC, ADC and Control Unit.

Current FEE BM@N configuration (March 2018) is based on IDEAS ASICs for Forward Silicon Detector, GEM detectors and CSC. According to upgrade plans for BM@N FEE for Si beam tracker, Si beam profiler, Forward Silicon Tracking Detectors also will be based on the same ASICs. This paper presents the design of the front-end electronics of the BM@N Si beam profiler:

 - Double-Sided Silicon Detectors – a coordinate plane with 2x128 measuring channels;
 - IDEAS ASICs – the front-end readout of DSSD;
 - Analog Devices ADC;
 - FPGA Xilinx – Control Unit.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Yulia</FirstName>
   <FamilyName>Ivanova</FamilyName>
   <Email>avinovayu@gmail.com</Email>
   <Affiliation>VBLHEP JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Sergei</FirstName>
   <FamilyName>Khabarov</FamilyName>
   <Email>sergei.khabarov@mail.ru</Email>
   <Affiliation>VBLHEP JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Yuri</FirstName>
   <FamilyName>Kovalev</FamilyName>
   <Email>humbalumumba@gmail.com</Email>
   <Affiliation>VBLHEP JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Yulia</FirstName>
   <FamilyName>Ivanova</FamilyName>
   <Email>avinovayu@gmail.com</Email>
   <Affiliation>VBLHEP JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
 </abstract>
 <abstract>
  <Id>127</Id>
  <Title>DijetGAN: A Generative-Adversarial Network Approach for the Simulation of QCD Dijet Events at the LHC</Title>
  <Content>We present a Generative-Adversarial Network (GAN) based on convolutional neural networks that are used to simulate the production of pairs of jets at the LHC. The GAN is trained on events generated using MadGraph5 + Pythia8, and Delphes3 fast detector simulation. A number of kinematic distributions both at Monte Carlo truth level and after the detector simulation can be reproduced by the generator network with a very good level of agreement. Our GAN can generate 1 million events in less than a minute and can be used to increase the size of Monte Carlo samples used by LHC experiments that are currently limited by the high CPU time required to generate events.</Content>
  <field id="content">We present a Generative-Adversarial Network (GAN) based on convolutional neural networks that are used to simulate the production of pairs of jets at the LHC. The GAN is trained on events generated using MadGraph5 + Pythia8, and Delphes3 fast detector simulation. A number of kinematic distributions both at Monte Carlo truth level and after the detector simulation can be reproduced by the generator network with a very good level of agreement. Our GAN can generate 1 million events in less than a minute and can be used to increase the size of Monte Carlo samples used by LHC experiments that are currently limited by the high CPU time required to generate events.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Michele</FirstName>
   <FamilyName>Faucci Giannelli</FamilyName>
   <Email>michele.faucci.giannelli@ed.ac.uk</Email>
   <Affiliation>University of Edinburgh</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Riccardo</FirstName>
   <FamilyName>Di Sipio</FamilyName>
   <Email>riccardo.di.sipio@cern.ch</Email>
   <Affiliation>University of Toronto</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Serena</FirstName>
   <FamilyName>Palazzo</FamilyName>
   <Email>serena.palazzo@cern.ch</Email>
   <Affiliation>University of Edinburgh</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Sana</FirstName>
   <FamilyName>Ketabchi Haghighat</FamilyName>
   <Email>sana.ketabchihaghighat@mail.utoronto.ca</Email>
   <Affiliation>University of Toronto</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Michele</FirstName>
   <FamilyName>Faucci Giannelli</FamilyName>
   <Email>michele.faucci.giannelli@ed.ac.uk</Email>
   <Affiliation>University of Edinburgh</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Machine Learning Algorithms and Big Data Analytics</Track>
 </abstract>
 <abstract>
  <Id>128</Id>
  <Title>APPLICATION OF QUANTUM TECHNOLOGIES  FOR THE DEVELOPMENT OF AN INTELLECTUAL CONTROL SYSTEM  TO SETUP CURRENTS OF THE CORRECTIVE MAGNETS  FOR THE BOOSTER SYNCHROTRON OF THE NICA FACILITY</Title>
  <Content>One of the promising directions in the development of robust control systems for complex physical facilities is the application of quantum computing for building intelligent controllers based on neural networks and genetic algorithms. The main advantage of the application of quantum technologies is the high speed of adaptation of the intelligent control system (ICS) to changing conditions of functioning. The most promising solution is to use IBM's quantum processor for quickly calculating Grover’s algorithm (GA) to find the “extremum” of the function of a set of control variables. For example, in the process of tuning the frequency of the HF stations of the NICA complex, unexpected “parasitic” oscillations may appear whose frequency spectrum cannot be predicted. In such conditions, the task of developing self-organizing ICS, capable of functioning and ensuring the achievement of the goal of control in emergency situations and information risk conditions, is relevant for the NICA complex.</Content>
  <field id="content">One of the promising directions in the development of robust control systems for complex physical facilities is the application of quantum computing for building intelligent controllers based on neural networks and genetic algorithms. The main advantage of the application of quantum technologies is the high speed of adaptation of the intelligent control system (ICS) to changing conditions of functioning. The most promising solution is to use IBM's quantum processor for quickly calculating Grover’s algorithm (GA) to find the “extremum” of the function of a set of control variables. For example, in the process of tuning the frequency of the HF stations of the NICA complex, unexpected “parasitic” oscillations may appear whose frequency spectrum cannot be predicted. In such conditions, the task of developing self-organizing ICS, capable of functioning and ensuring the achievement of the goal of control in emergency situations and information risk conditions, is relevant for the NICA complex.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Dmitrii</FirstName>
   <FamilyName>Monakhov</FamilyName>
   <Email>cornflyer@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Andrey</FirstName>
   <FamilyName>Reshetnikov</FamilyName>
   <Email>agreshetnikov@gmail.com</Email>
   <Affiliation>Ph.D.</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Dmitrii</FirstName>
   <FamilyName>Monakhov</FamilyName>
   <Email>cornflyer@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>None</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>129</Id>
  <Title>Realistic simulation of the MPD Time Projection Chamber with Garfield.</Title>
  <Content>The detailed simulation of electron drifting in the MPD TPC was made with CERN Garfield toolkit for the simulation of gas particle detectors. For electron transporting were used the Ar+CH4 gas mixture with impact of magnetic and electric fields. Ionization processes were investigated in the wire planes area near readout chambers of the TPC.</Content>
  <field id="content">The detailed simulation of electron drifting in the MPD TPC was made with CERN Garfield toolkit for the simulation of gas particle detectors. For electron transporting were used the Ar+CH4 gas mixture with impact of magnetic and electric fields. Ionization processes were investigated in the wire planes area near readout chambers of the TPC.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Alexander</FirstName>
   <FamilyName>Bychkov</FamilyName>
   <Email>abychkov@jinr.ru</Email>
   <Affiliation>LHEP</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Oleg</FirstName>
   <FamilyName>Rogachevskiy</FamilyName>
   <Email>rogachevsky@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Alexander</FirstName>
   <FamilyName>Bychkov</FamilyName>
   <Email>abychkov@jinr.ru</Email>
   <Affiliation>LHEP</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Computing for Large Scale Facilities (LHC, FAIR, NICA, SKA, PIC, XFEL, ELI, etc.)</Track>
 </abstract>
 <abstract>
  <Id>130</Id>
  <Title>Global Neutrino Analysis framework and GPU based computations</Title>
  <Content>GNA is a high-performance fitting framework developed for the data analysis of the neutrino experiments. The framework is based on data flow principles: an experiment model is represented by the computational graph of simple functions as separate nodes that are computed lazily.
In this work, we describe the GPU support library for GNA named cuGNA which uses CUDA toolkit. This library is implemented to enable both the performance of GPU and the versatility of data flow approach. We have added GPU-based node implementation to the existing library as well as implemented GNA core features that make GPU support hidden from the end user.        
Current status of CUDA computations in GNA, tests on real-life computational graphs, and performance comparison to CPU-based models are presented in this work.</Content>
  <field id="content">GNA is a high-performance fitting framework developed for the data analysis of the neutrino experiments. The framework is based on data flow principles: an experiment model is represented by the computational graph of simple functions as separate nodes that are computed lazily.
In this work, we describe the GPU support library for GNA named cuGNA which uses CUDA toolkit. This library is implemented to enable both the performance of GPU and the versatility of data flow approach. We have added GPU-based node implementation to the existing library as well as implemented GNA core features that make GPU support hidden from the end user.        
Current status of CUDA computations in GNA, tests on real-life computational graphs, and performance comparison to CPU-based models are presented in this work.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Maxim</FirstName>
   <FamilyName>Gonchar</FamilyName>
   <Email>gonchar@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Anna</FirstName>
   <FamilyName>Fatkina</FamilyName>
   <Email>fatkina.a.i@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Konstantin</FirstName>
   <FamilyName>Treskov</FamilyName>
   <Email>treskov@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Dmitry</FirstName>
   <FamilyName>Naumov</FamilyName>
   <Email>dnaumov@jinr.ru</Email>
   <Affiliation>DLNP JINR</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Liudmila</FirstName>
   <FamilyName>Kolupaeva</FamilyName>
   <Email>ldkolupaeva@yandex.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Anastasia</FirstName>
   <FamilyName>Kalitkina</FamilyName>
   <Email>mir8796@gmail.com</Email>
   <Affiliation>JINR, DLNP, University Centre, MSU</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Anna</FirstName>
   <FamilyName>Fatkina</FamilyName>
   <Email>fatkina.a.i@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Computations with Hybrid Systems (CPU, GPU, coprocessors)</Track>
 </abstract>
 <abstract>
  <Id>131</Id>
  <Title>PROGRAM MANAGER FOR DC-280 CYCLOTRON CONTROL SYSTEM</Title>
  <Content>March 25, 2019 the experimental hall of the Super-heavy Elements Factory (SHE) was opened at the FLNR JINR and its basic facility – the DC-280 cyclotron was launched. The cyclotron control system software contains modules that must be serviced to ensure reliability and fault tolerance. The Program Manager was developed to accomplish this. It performs start, stop and status monitoring of project modules. As a feature it is able to update programs and has voice informer to alarm the failures. This paper describes the algorithm and user interface of the Program Manager.</Content>
  <field id="content">March 25, 2019 the experimental hall of the Super-heavy Elements Factory (SHE) was opened at the FLNR JINR and its basic facility – the DC-280 cyclotron was launched. The cyclotron control system software contains modules that must be serviced to ensure reliability and fault tolerance. The Program Manager was developed to accomplish this. It performs start, stop and status monitoring of project modules. As a feature it is able to update programs and has voice informer to alarm the failures. This paper describes the algorithm and user interface of the Program Manager.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Veronika</FirstName>
   <FamilyName>Zabanova</FamilyName>
   <Email>badver@jinr.ru</Email>
   <Affiliation>FLNR, JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Vitali</FirstName>
   <FamilyName>Aleinikov</FamilyName>
   <Email>vitalirus@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Kirill</FirstName>
   <FamilyName>Sychev</FamilyName>
   <Email>sychev@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Sergei</FirstName>
   <FamilyName>Pashchenko</FamilyName>
   <Email>svpashch@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Veronika</FirstName>
   <FamilyName>Zabanova</FamilyName>
   <Email>badver@jinr.ru</Email>
   <Affiliation>FLNR, JINR</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>132</Id>
  <Title>Development of the timing system of the NICA</Title>
  <Content>The report is devoted to the issues of creating a unified timing system for the NICA complex. The created system will be based on the “White Rabbit” technology, the implementation of this technology will be considered. 
The problem of adjusting the phases of the RF during the transfer of the beam from the accelerator to the accelerator will also be discussed.
Particular attention will be paid to the development of hardware for the synchronization system.</Content>
  <field id="content">The report is devoted to the issues of creating a unified timing system for the NICA complex. The created system will be based on the “White Rabbit” technology, the implementation of this technology will be considered. 
The problem of adjusting the phases of the RF during the transfer of the beam from the accelerator to the accelerator will also be discussed.
Particular attention will be paid to the development of hardware for the synchronization system.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Ilya</FirstName>
   <FamilyName>Shirikov</FamilyName>
   <Email>shirikov@bk.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Ilya</FirstName>
   <FamilyName>Shirikov</FamilyName>
   <Email>shirikov@bk.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>None</ContributionType>
  <Track>Triggering, Data Acquisition, Control Systems</Track>
 </abstract>
 <abstract>
  <Id>133</Id>
  <Title>EI3 – The ATLAS EventIndex for LHC Run 3</Title>
  <Content>The ATLAS Event Index provides since 2015 a good and reliable service for the initial use cases (mainly event picking) and several additional ones, such as production consistency checks, duplicate event detection and measurements of the overlaps of trigger chains and derivation datasets. LHC Run 3 will see increased data-taking and simulation production rates, with which the current infrastructure would still cope but may be stretched to its limits by the end of Run 3. This talk describes a new implementation of the front and back-end services that will be able to provide at least the same functionality as the current one for increased data ingestion and search rates and with increasing volumes of stored data. It is based on a set of HBase tables, with schemas derived from the current Oracle implementation, coupled to Apache Phoenix for data access; in this way we will add to the advantages of a BigData based storage system the possibility of SQL as well as NoSQL data access, allowing us to re-use most of the existing code for metadata integration.</Content>
  <field id="content">The ATLAS Event Index provides since 2015 a good and reliable service for the initial use cases (mainly event picking) and several additional ones, such as production consistency checks, duplicate event detection and measurements of the overlaps of trigger chains and derivation datasets. LHC Run 3 will see increased data-taking and simulation production rates, with which the current infrastructure would still cope but may be stretched to its limits by the end of Run 3. This talk describes a new implementation of the front and back-end services that will be able to provide at least the same functionality as the current one for increased data ingestion and search rates and with increasing volumes of stored data. It is based on a set of HBase tables, with schemas derived from the current Oracle implementation, coupled to Apache Phoenix for data access; in this way we will add to the advantages of a BigData based storage system the possibility of SQL as well as NoSQL data access, allowing us to re-use most of the existing code for metadata integration.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Fedor</FirstName>
   <FamilyName>Prokoshin</FamilyName>
   <Email>prof@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Evgeny</FirstName>
   <FamilyName>Alexandrov</FamilyName>
   <Email>aleksand@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Julius</FirstName>
   <FamilyName>Hrivnac</FamilyName>
   <Email>julius.hrivnac@cern.ch</Email>
   <Affiliation>LAL Orsay</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Andrei</FirstName>
   <FamilyName>Kazymov</FamilyName>
   <Email>kazymai@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Mikhail</FirstName>
   <FamilyName>Mineev</FamilyName>
   <Email>mineev@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Grigori</FirstName>
   <FamilyName>Rybkin</FamilyName>
   <Email>grigori.rybkine@cern.ch</Email>
   <Affiliation>LAL, Univ. Paris-Sud</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Javier</FirstName>
   <FamilyName>Sánchez</FamilyName>
   <Email>javier.sanchez@cern.ch</Email>
   <Affiliation>Instituto de Fisica Corpuscular (IFIC)</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>José</FirstName>
   <FamilyName>Salt Cairols</FamilyName>
   <Email>jose.salt@cern.ch</Email>
   <Affiliation>Instituto de Fisica Corpuscular (IFIC)</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Miguel</FirstName>
   <FamilyName>Villaplana</FamilyName>
   <Email>miguel.villaplana.perez@cern.ch</Email>
   <Affiliation>Università degli Studi e INFN Milano</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Igor</FirstName>
   <FamilyName>Alexandrov</FamilyName>
   <Email>alexand@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Zbigniew</FirstName>
   <FamilyName>Baranowski</FamilyName>
   <Email>zbigniew.baranowski@cern.ch</Email>
   <Affiliation>CERN</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Dario</FirstName>
   <FamilyName>Barberis</FamilyName>
   <Email>dario.barberis@ge.infn.it</Email>
   <Affiliation>University and INFN Genova (Italy)</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Gancho</FirstName>
   <FamilyName>Dimitrov</FamilyName>
   <Email>gancho.dimitrov@cern.ch</Email>
   <Affiliation>CERN</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Álvaro</FirstName>
   <FamilyName>Fernández Casaní</FamilyName>
   <Email>alvaro.fernandez.casani@cern.ch</Email>
   <Affiliation>Instituto de Fisica Corpuscular (IFIC)</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Elizabeth</FirstName>
   <FamilyName>Gallas</FamilyName>
   <Email>elizabeth.gallas@physics.ox.ac.uk</Email>
   <Affiliation>University of Oxford</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Carlos</FirstName>
   <FamilyName>García Montoro</FamilyName>
   <Email>carlos.garcia.montoro@cern.ch</Email>
   <Affiliation>Instituto de Fisica Corpuscular (IFIC)</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Santiago</FirstName>
   <FamilyName>González de la Hoz</FamilyName>
   <Email>santiago.gonzalezdelahoz@cern.ch</Email>
   <Affiliation>Instituto de Fisica Corpuscular (IFIC)</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Fedor</FirstName>
   <FamilyName>Prokoshin</FamilyName>
   <Email>prof@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Speaker>
  <ContributionType>None</ContributionType>
  <Track>Research Data Infrastructures</Track>
  <Track>Distributed Computing. GRID &amp; Cloud Computing</Track>
  <Track>Computing for Large Scale Facilities (LHC, FAIR, NICA, SKA, PIC, XFEL, ELI, etc.)</Track>
  <Track>Non-relational Databases and Heterogeneous Repositories</Track>
 </abstract>
 <abstract>
  <Id>134</Id>
  <Title>Simulating Lattice QCD on the "Govorun" Supercomputer</Title>
  <Content>Lattice Quantum Chromodynamics (QCD) is a well-established non-perturbative approach
to the theory of strong interactions, QCD. It provides a framework for numerical studies
of various complex problems of QCD. Such computations are numerically very demanding
and require the most powerful modern supercomputers and algorithms. Within this talk, the lattice
QCD simulations which are carried out on "Govorun" supercomputer are discussed.
The basic algorithms and their implementation on "Govorun" architecture are reviewed.
Important physical results and projects which are studied on "Govorun", including
QCD at finite temperature, isospin and baryon density, are presented.</Content>
  <field id="content">Lattice Quantum Chromodynamics (QCD) is a well-established non-perturbative approach
to the theory of strong interactions, QCD. It provides a framework for numerical studies
of various complex problems of QCD. Such computations are numerically very demanding
and require the most powerful modern supercomputers and algorithms. Within this talk, the lattice
QCD simulations which are carried out on "Govorun" supercomputer are discussed.
The basic algorithms and their implementation on "Govorun" architecture are reviewed.
Important physical results and projects which are studied on "Govorun", including
QCD at finite temperature, isospin and baryon density, are presented.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Andrey</FirstName>
   <FamilyName>Kotov</FamilyName>
   <Email>kotov@itep.ru</Email>
   <Affiliation>Institute for Theoretical and Experimental Physics</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Victor</FirstName>
   <FamilyName>Braguta</FamilyName>
   <Email>braguta@itep.ru</Email>
   <Affiliation>ITEP</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Aleksandr</FirstName>
   <FamilyName>Nikolaev</FamilyName>
   <Email>aleksandr.nikolaev@swansea.ac.uk</Email>
   <Affiliation>Swansea University</Affiliation>
  </PrimaryAuthor>
  <PrimaryAuthor>
   <FirstName>Nikita</FirstName>
   <FamilyName>Astrakhantsev</FamilyName>
   <Email>nikita.astronaut@gmail.com</Email>
   <Affiliation>JINR</Affiliation>
  </PrimaryAuthor>
  <Speaker>
   <FirstName>Andrey</FirstName>
   <FamilyName>Kotov</FamilyName>
   <Email>kotov@itep.ru</Email>
   <Affiliation>Institute for Theoretical and Experimental Physics</Affiliation>
  </Speaker>
  <ContributionType>Sectional</ContributionType>
  <Track>Computations with Hybrid Systems (CPU, GPU, coprocessors)</Track>
 </abstract>
 <abstract>
  <Id>135</Id>
  <Title>Simulation of spectra of cylindrical neutron counters using the GEANT-4 package</Title>
  <Content>It’s commonly supposed that the amplitude spectrum of the helium proportional counter at irradiation by thermal and cold neutrons has a peak of full absorption with energy of 768 keV and two small “shelves”, caused by boundary effects from falling of charged particles (of proton or tritium nucleus) in the detector wall.  Simulation of amplitude spectra of cylindrical counters with different gas filling is presented in the paper. The possibility of the third peak, not coinciding with that of full absorption, is shown, while the peak position depends on the ratio of the path length towards the counter diameter. The results obtained may be of interest in the development of low efficiency neutron detectors and neutron monitors.</Content>
  <field id="content">It’s commonly supposed that the amplitude spectrum of the helium proportional counter at irradiation by thermal and cold neutrons has a peak of full absorption with energy of 768 keV and two small “shelves”, caused by boundary effects from falling of charged particles (of proton or tritium nucleus) in the detector wall.  Simulation of amplitude spectra of cylindrical counters with different gas filling is presented in the paper. The possibility of the third peak, not coinciding with that of full absorption, is shown, while the peak position depends on the ratio of the path length towards the counter diameter. The results obtained may be of interest in the development of low efficiency neutron detectors and neutron monitors.</field>
  <field id="summary"/>
  <PrimaryAuthor>
   <FirstName>Andrey</FirstName>
   <FamilyName>Churakov</FamilyName>
   <Email>churakov@nf.jinr.ru</Email>
   <Affiliation>FLNP JINR</Affiliation>
  </PrimaryAuthor>
  <Co-Author>
   <FirstName>Aleksey</FirstName>
   <FamilyName>Kurilkin</FamilyName>
   <Email>akurilkin@jinr.ru</Email>
   <Affiliation>JINR</Affiliation>
  </Co-Author>
  <Co-Author>
   <FirstName>Saiz Lomas</FirstName>
   <FamilyName>Juan</FamilyName>
   <Email>js2604@york.ac.uk</Email>
   <Affiliation>University of York</Affiliation>
  </Co-Author>
  <Speaker>
   <FirstName>Andrey</FirstName>
   <FamilyName>Churakov</FamilyName>
   <Email>churakov@nf.jinr.ru</Email>
   <Affiliation>FLNP JINR</Affiliation>
  </Speaker>
  <ContributionType>None</ContributionType>
  <Track>Detector &amp; Nuclear Electronics</Track>
 </abstract>
</AbstractBook>